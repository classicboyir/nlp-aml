{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import azureml.core\n",
        "\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667539874911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "# create config.json with subscription_id, workspace_name and resource_group settings\n",
        "\n",
        "#connect to the workspace\n",
        "ml_client = MLClient.from_config(DefaultAzureCredential())\n",
        "\n",
        "print(ml_client)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667541558914
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get larger datasets: http://jmcauley.ucsd.edu/data/amazon/"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667542308747
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz -P data/"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "pdf_main = getDF('data/reviews_Automotive_5.json.gz')\n",
        "pdf_main.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667542315790
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_main.loc[pdf_main['overall'] >= 4, 'sentiment'] = 1\n",
        "pdf_main.loc[pdf_main['overall'] < 3, 'sentiment'] = 0\n",
        "\n",
        "pdf_main.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667542319038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_datasets(pdf_target_training, label = 'sentiment'):\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(pdf_target_training.drop(label, axis=1), pdf_target_training[label],\n",
        "                                                        stratify=pdf_target_training[label],\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.20)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        "                                                        stratify=y_test_val,\n",
        "                                                        shuffle=True,\n",
        "                                                        test_size=0.5)\n",
        "    pdf_X_train = X_train\n",
        "    pdf_X_val = X_val\n",
        "    pdf_X_test = X_test\n",
        "\n",
        "    pdf_X_train['sentiment'] = y_train\n",
        "    pdf_X_val['sentiment'] = y_val\n",
        "    pdf_X_test['sentiment'] = y_test\n",
        "    \n",
        "    print(f'Total records for: \"pdf_X_train\": [{pdf_X_train.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_val\": [{pdf_X_val.shape[0]}]')\n",
        "    print(f'Total records for: \"pdf_X_test\": [{pdf_X_test.shape[0]}]')\n",
        "    \n",
        "    return pdf_X_train, pdf_X_val, pdf_X_test"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667542323097
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_train, pdf_val, pdf_test = generate_datasets(pdf_main[['reviewText', 'sentiment']].dropna(), 'sentiment')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667549263708
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare MLTable data and register Datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "data_dir = \"./data/table\"\r\n",
        "os.makedirs(data_dir, exist_ok=True)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667549275905
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {data_dir}/MLTable\r\n",
        "paths: \r\n",
        "  - file: ./*.csv\r\n",
        "transformations: \r\n",
        "  - read_delimited: \r\n",
        "      delimiter: ',' \r\n",
        "      encoding: 'ascii' \r\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "\n",
        "# Load Training set\n",
        "pdf_train.to_csv(os.path.join(data_dir, \"data.csv\"))\n",
        "\n",
        "ds_train_set = Data(\n",
        "    path=data_dir,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"Small amazon review for sentiment analysis [train set]\",\n",
        "    name=\"train_setv2\"\n",
        ")\n",
        "ml_client.data.create_or_update(ds_train_set)\n",
        "\n",
        "# Load Validataion\n",
        "\n",
        "pdf_val.to_csv('./data/table/data.csv')\n",
        "\n",
        "ds_validate_set = Data(\n",
        "    path=data_dir,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"Small amazon review for sentiment analysis [validate set]\",\n",
        "    name=\"validate_setv2\"\n",
        ")\n",
        "ml_client.data.create_or_update(ds_validate_set)\n",
        "\n",
        "pdf_test.to_csv('./data/table/data.csv')\n",
        "\n",
        "ds_test_set = Data(\n",
        "    path=data_dir,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"Small amazon review for sentiment analysis [test set]\",\n",
        "    name=\"test_setv2\"\n",
        ")\n",
        "ml_client.data.create_or_update(ds_test_set)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667549372003
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "# Retrieve an already attached Azure Machine Learning Compute.\n",
        "cluster_name = \"gpucluster\"\n",
        "compute_target = ml_client.compute.get(cluster_name)\n",
        "print(compute_target)\n",
        "\n",
        "\n",
        "env = Environment(\n",
        "   name=\"AzureML-AutoML-DNN-Text-GPU\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667585619944
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azure.ai.ml import Input, command\n",
        "from azure.ai.ml.entities import Data, Environment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "source_directory = \"./project\"\n",
        "\n",
        "job_inputs = { \"training-dataset\": Input(path=ds_train_set.id),\n",
        "               \"val-dataset\": Input(path=ds_validate_set.id),\n",
        "               \"test-dataset\": Input(path=ds_test_set.id),\n",
        "               \"target-name\": 'sentiment',   \n",
        "               \"text-field\": 'reviewText',\n",
        "                \"is-test\": 0,\n",
        "                \"is-final\": 0,\n",
        "                \"is-jump\": 1,\n",
        "                \"is-local\": 0,\n",
        "                \"evaluation-strategy\": \"epoch\"\n",
        "}\n",
        "\n",
        "job = command(\n",
        "    code=source_directory,\n",
        "    command=\"train_transformer.py --val-dataset ${{inputs.val_dataset}} --training-dataset ${{inputs.training-dataset}} --test-dataset ${{inputs.test-dataset}} --target-name ${{inputs.target-name}}\",\n",
        "    inputs=job_inputs,\n",
        "    environment=env,\n",
        "    compute=cluster_name,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667585620307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        '--base-checkpoint': choice(\"bert-base-cased\"), #, \"bert-base-cased\"), # , \"bert-large-cased\", \"microsoft/deberta-v3-small\", \"distilbert-base-uncased\", \"bert-base-uncased\"),\n",
        "        '--batch-size': choice(8),\n",
        "        '--no-epochs': choice(4),\n",
        "        '--learning-rate': choice(5.5e-5, 5e-5, 4.5e-5, 4e-5, 5.5e-5, 6e-5, 3.5e-5, 6.5e-5),\n",
        "        '--warmup-steps': choice(0),\n",
        "        '--weight-decay': choice(0.0),\n",
        "        '--adam-beta1': choice(0.9),\n",
        "        '--adam-beta2': choice(0.999),\n",
        "        '--adam-epsilon': choice(1e-8)\n",
        "    }\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526912908
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     hyperparameter_sampling=ps,\n",
        "                                     policy=policy,\n",
        "                                     primary_metric_name='eval_f1_weighted',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=20,\n",
        "                                     max_concurrent_runs=3)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526918710
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "hd_step_name='HyperDrive_Step'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hyperdrive_config,\n",
        "    allow_reuse=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526921140
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cpu_compute = ComputeTarget(workspace=ws, name=\"gpucluster\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526936678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_cpu = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526944720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Register_Best_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--is-test', 0,\n",
        "                                                  '--test-run-id', '',\n",
        "                                                  '--metric-name', 'test_f1_weighted',\n",
        "                                                  '--second-metric', 'test_f1',\n",
        "                                                  '--target-name', 'sentiment',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "register_model_step.run_after(hd_step)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526947796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "# conda_dep.add_pip_package(\"azureml-sdk\")\n",
        "# conda_dep.env\n",
        "\n",
        "rcfg = RunConfiguration() # conda_dependencies=conda_dep)\n",
        "rcfg.environment = env_cpu\n",
        "\n",
        "deploy_model_step = PythonScriptStep(script_name='deploy_model.py',\n",
        "                                       source_directory=source_directory,\n",
        "                                       name=\"Deploy_Latest_Model\",\n",
        "                                       compute_target=cpu_compute,\n",
        "                                       arguments=['--endpoint-name', 'sentiment-endpoint',\n",
        "                                                  '--model-name', 'sentiment_classifier'],\n",
        "                                       allow_reuse=True,\n",
        "                                       runconfig=rcfg)\n",
        "\n",
        "deploy_model_step.run_after(register_model_step)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526956328
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp = Experiment(workspace=ws, name='transformer_hp')\n",
        "steps = [deploy_model_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526971263
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.submit(exp.name, credential_passthrough=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526989177
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "timenow = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "\n",
        "pipeline_name = f\"Sentiment-Classifier-{timenow}-Pipeline\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667526999775
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.integrations import AzureMLCallback\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from torchsummary import summary\n",
    "\n",
    "sys.path.append(os.path.join(os.path.join(os.getcwd(), \"..\"), 'project'))\n",
    "from train_transformer import get_model, adjust_tokenizer, compute_metrics, get_encode_labels, tokenize_function, generate_tokenized_dataset, get_datasets, test_model\n",
    "from utils import *\n",
    "# from utils import get_valid_runs, get_highest_performing_model, get_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "import azureml\n",
    "import mlflow\n",
    "from azureml.core import Workspace, Dataset, Environment\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "print(\"MLflow version:\", mlflow.version.VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "# mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "script_folder = './project'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='transformer_hp')\n",
    "# mlflow.set_experiment('transformer_hp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'output_120'\n",
    "model_directory = f'{dir}/outputs/model'\n",
    "print(f'the output path: [{model_directory}]')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_directory, num_labels=121)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "le=joblib.load(model_directory + '/labelEncoder.joblib')\n",
    "print('Model objects and their dependencies are loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "parameter_target = None\n",
    "for name, parameter in model.named_parameters():\n",
    "    if name == 'bert.encoder.layer.2.attention.self.query.weight':\n",
    "        parameter_target = parameter\n",
    "        print(name)\n",
    "        counter += 1\n",
    "    # print(parameter)\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=121)\n",
    "\n",
    "counter = 0\n",
    "parameter_target_base = None\n",
    "for name, parameter in model_base.named_parameters():\n",
    "    if name == 'bert.encoder.layer.2.attention.self.query.weight':\n",
    "        parameter_target_base = parameter\n",
    "        print(name)\n",
    "        counter += 1\n",
    "    # print(parameter)\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_target.to(torch.device('cpu')) == parameter_target_base.to(torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_2 = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=121)\n",
    "\n",
    "counter = 0\n",
    "parameter_target_base_2 = None\n",
    "for name, parameter in model_base_2.named_parameters():\n",
    "    if name == 'bert.encoder.layer.2.attention.self.query.weight':\n",
    "        parameter_target_base_2 = parameter\n",
    "        print(name)\n",
    "        counter += 1\n",
    "    # print(parameter)\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_target.to(torch.device('cpu')) == parameter_target_base_2.to(torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_target.to(torch.device('cpu')) == parameter_target_base_2.to(torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=12)\n",
    "\n",
    "li_shapes = []\n",
    "counter = 0\n",
    "parameter_target_base = None\n",
    "for name, parameter in model_base.named_parameters():\n",
    "    x = parameter.shape[0]\n",
    "    y = parameter.shape[0]\n",
    "    li_shapes.append(x * y)\n",
    "    # if name == 'bert.encoder.layer.2.attention.self.query.weight':\n",
    "    #     parameter_target_base = parameter\n",
    "    #     print(name)\n",
    "    #     counter += 1\n",
    "    # print(parameter)\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(li_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
